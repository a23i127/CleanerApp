//
//  ViewController.swift
//  RealtimeObjectCounting
//

import UIKit
import AVFoundation
import CoreML
import Vision

class ViewController: UIViewController, UINavigationControllerDelegate, UIImagePickerControllerDelegate, AVCapturePhotoCaptureDelegate {
    
    enum ImageCaptureOrientation {
        case portrait
        case landscape
    }

    struct FixedImageResult {
        var image: UIImage
        var originalOrientation: ImageCaptureOrientation
    }
        var captureSession: AVCaptureSession!
        var photoOutput: AVCapturePhotoOutput!
        var previewLayer: AVCaptureVideoPreviewLayer!
    @IBOutlet weak var cameraView: UIImageView! // ã‚«ãƒ¡ãƒ©ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºç”¨ï¼ˆã‚ã¨ã§é™æ­¢ç”»ã‚’è¦‹ã›ã‚‹ç”¨ã«ï¼‰
    @IBOutlet weak var footerView: UIView! // çµæžœè¡¨ç¤ºç”¨ãƒ“ãƒ¥ãƒ¼
// çµæžœè¡¨ç¤ºãƒ©ãƒ™ãƒ«
    @IBOutlet weak var textView: UITextView!
    private let imagePicker = UIImagePickerController()
    private var yoloModel: VNCoreMLModel!
    private var objectCounter: [String: Int] = [:]
    var result: FixedImageResult? = nil
    override func viewDidLoad() {
        super.viewDidLoad()
        setupCamera()
        // ãƒ©ãƒ™ãƒ«ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

        NSLayoutConstraint.activate([
            textView.leadingAnchor.constraint(equalTo: footerView.leadingAnchor, constant: 16),
            textView.trailingAnchor.constraint(equalTo: footerView.trailingAnchor, constant: -16),
            textView.topAnchor.constraint(equalTo: footerView.topAnchor, constant: 8),
            textView.bottomAnchor.constraint(equalTo: footerView.bottomAnchor, constant: -8)
        ])

        // ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        do {
            yoloModel = try VNCoreMLModel(for: yolov8l().model) // ã‚¯ãƒ©ã‚¹åã¯è‡ªåˆ†ã®ã«åˆã‚ã›ã¦ã­
        } catch {
            print("ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: \(error)")
        }

    }
    func setupCamera() {
            // 1. ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
            captureSession = AVCaptureSession()
            captureSession.sessionPreset = .photo

            // 2. å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ï¼ˆã‚«ãƒ¡ãƒ©ï¼‰
            guard let camera = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back),
                  let input = try? AVCaptureDeviceInput(device: camera),
                  captureSession.canAddInput(input) else {
                print("ã‚«ãƒ¡ãƒ©ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å¤±æ•—")
                return
            }
            captureSession.addInput(input)

            // 3. å‡ºåŠ›ï¼ˆå†™çœŸï¼‰
            photoOutput = AVCapturePhotoOutput()
            guard captureSession.canAddOutput(photoOutput) else { return }
            captureSession.addOutput(photoOutput)

            // 4. ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼
            previewLayer = AVCaptureVideoPreviewLayer(session: captureSession)
            previewLayer.videoGravity = .resizeAspectFill
            previewLayer.frame = view.bounds
            view.layer.insertSublayer(previewLayer, at: 0)

            // ðŸ”’ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚‚ç¸¦å›ºå®š
            if let conn = previewLayer.connection, conn.isVideoOrientationSupported {
                conn.videoOrientation = .portrait
            }

            captureSession.startRunning()
        }
    @IBAction func takePhoto(_ sender: Any) {
        let settings = AVCapturePhotoSettings()
                
                // ðŸ”’ æ’®å½±ç”»åƒã‚‚ç¸¦å›ºå®š
                if let conn = photoOutput.connection(with: .video), conn.isVideoOrientationSupported {
                    conn.videoOrientation = .portrait
                }

                photoOutput.capturePhoto(with: settings, delegate: self)
    }
    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
            guard let imageData = photo.fileDataRepresentation(),
                  let image = UIImage(data: imageData) else {
                print("ç”»åƒå–å¾—å¤±æ•—")
                return
            }
            // è¡¨ç¤º or ä¿å­˜
        let fixedImageObj = fixedOrientationWithMetadata(image: image)
        analyze(image: fixedImageObj.image,orientation: fixedImageObj.originalOrientation)
        }

    func analyze(image: UIImage, orientation: ImageCaptureOrientation) {
        guard let cgImage = image.cgImage else { return print(1)}
        cameraView.image = image  // æ’®ã£ãŸç”»åƒã‚’è¡¨
               // æ—¢å­˜ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤ï¼ˆå†æç”»æ™‚ã«é‡ãªã‚‰ãªã„ã‚ˆã†ã«ï¼‰
        cameraView.subviews.forEach { $0.removeFromSuperview() }

        let request = VNCoreMLRequest(model: yoloModel) { request, error in
            guard let results = request.results as? [VNRecognizedObjectObservation] else { return}

            self.objectCounter.removeAll()

            for observation in results {
                guard let label = observation.labels.first?.identifier else { continue }
                self.objectCounter[label, default: 0] += 1

                let boundingBox = observation.boundingBox
                DispatchQueue.main.async {
                    self.drawBoundingBox(on: self.cameraView, box: boundingBox, label: label, orientation: orientation)
                }
            }

            let sorted = self.objectCounter.sorted(by: { $0.1 > $1.1 })
            DispatchQueue.main.async {
                print(sorted)
                self.textView.text = sorted.map { "\($0.key): \($0.value)å€‹" }.joined(separator: "\n")
            }
        }

        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        try? handler.perform([request])
    }
    func drawBoundingBox(on imageView: UIImageView, box: CGRect, label: String,orientation: ImageCaptureOrientation) {
        let imageSize = imageView.bounds.size
        let rect: CGRect
        switch orientation {
        case .portrait:
            rect = CGRect(
                x: box.origin.x * imageSize.width,
                y: (1 - box.origin.y - box.height) * imageSize.height,
                width: box.width * imageSize.width,
                height: box.height * imageSize.height
            )
        case .landscape:
            rect = CGRect(
                x: (1 - box.origin.y - box.height) * imageSize.width,
                y: box.origin.x * imageSize.height,
                width: box.height * imageSize.width,
                height: box.width * imageSize.height
            )
        }
        // ä»¥ä¸‹ã¯ãã®ã¾ã¾OK
        let boxView = UIView(frame: rect)
        boxView.layer.borderWidth = 2
        boxView.layer.borderColor = UIColor.red.cgColor
        boxView.backgroundColor = UIColor.clear
        imageView.addSubview(boxView)

        let labelView = UILabel(frame: CGRect(x: rect.origin.x, y: rect.origin.y - 20, width: 120, height: 20))
        labelView.text = label
        labelView.textColor = .white
        labelView.backgroundColor = UIColor.black.withAlphaComponent(0.6)
        labelView.font = UIFont.boldSystemFont(ofSize: 14)
        imageView.addSubview(labelView)
    }
    func imagePickerControllerDidCancel(_ picker: UIImagePickerController) {
        picker.dismiss(animated: true)
    }
    func fixedOrientationWithMetadata(image: UIImage) -> FixedImageResult {
        let orientation: ImageCaptureOrientation
        if image.imageOrientation == .left || image.imageOrientation == .right ||
            image.imageOrientation == .leftMirrored || image.imageOrientation == .rightMirrored {
            orientation = .portrait
        } else {
            orientation = .landscape
        }

        // æœ¬å½“ã«æç”»ã™ã‚‹ã‚µã‚¤ã‚ºï¼ˆå¹…ã¨é«˜ã•ã‚’é€†ã«ã™ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆãŒã‚ã‚‹ï¼‰
        var drawSize = image.size
        if orientation == .landscape {
            drawSize = CGSize(width: image.size.height, height: image.size.width)
        }

        UIGraphicsBeginImageContextWithOptions(drawSize, false, image.scale)
        guard let context = UIGraphicsGetCurrentContext() else {
            UIGraphicsEndImageContext()
            return FixedImageResult(image: image, originalOrientation: orientation)
        }
        
        // å›žè»¢è£œæ­£
        switch image.imageOrientation {
       
        case .up:
            context.rotate(by: -.pi / 2)
            context.translateBy(x: -image.size.width, y: 0)
        case .down:
            context.rotate(by: .pi)
            context.translateBy(x: -image.size.width, y: -image.size.height)
        default:
            break
        }

        image.draw(in: CGRect(origin: .zero, size: image.size))
        let normalizedImage = UIGraphicsGetImageFromCurrentImageContext()
        UIGraphicsEndImageContext()
        print(image.size)
        print(normalizedImage!.size)
        return FixedImageResult(
            image: normalizedImage ?? image,
            originalOrientation: orientation
        )
    }
}
extension UIImage {
 
    func fixedOrientation() -> UIImage? {
 
        guard imageOrientation != UIImage.Orientation.up else {
            //This is default orientation, don't need to do anything
            return self.copy() as? UIImage
        }
 
        guard let cgImage = self.cgImage else {
            //CGImage is not available
            return nil
        }
 
        guard let colorSpace = cgImage.colorSpace, let ctx = CGContext(data: nil, width: Int(size.width), height: Int(size.height), bitsPerComponent: cgImage.bitsPerComponent, bytesPerRow: 0, space: colorSpace, bitmapInfo: CGImageAlphaInfo.premultipliedLast.rawValue) else {
            return nil //Not able to create CGContext
        }
 
        var transform: CGAffineTransform = CGAffineTransform.identity
 
        switch imageOrientation {
        case .down, .downMirrored:
            transform = transform.translatedBy(x: size.width, y: size.height)
            transform = transform.rotated(by: CGFloat.pi)
            break
        case .left, .leftMirrored:
            transform = transform.translatedBy(x: size.width, y: 0)
            transform = transform.rotated(by: CGFloat.pi / 2.0)
            break
        case .right, .rightMirrored:
            transform = transform.translatedBy(x: 0, y: size.height)
            transform = transform.rotated(by: CGFloat.pi / -2.0)
            break
        case .up, .upMirrored:
            break
        }
 
        //Flip image one more time if needed to, this is to prevent flipped image
        switch imageOrientation {
        case .upMirrored, .downMirrored:
            transform = transform.translatedBy(x: size.width, y: 0)
            transform = transform.scaledBy(x: -1, y: 1)

        case .leftMirrored, .rightMirrored:
            transform = transform.translatedBy(x: size.height, y: 0)
            transform = transform.scaledBy(x: -1, y: 1)

        case .up, .down, .left, .right:
            break
        }
 
        ctx.concatenate(transform)
 
        switch imageOrientation {
        case .left, .leftMirrored, .right, .rightMirrored:
            ctx.draw(self.cgImage!, in: CGRect(x: 0, y: 0, width: size.height, height: size.width))
        default:
            ctx.draw(self.cgImage!, in: CGRect(x: 0, y: 0, width: size.width, height: size.height))
            break
        }
 
        guard let newCGImage = ctx.makeImage() else { return nil }
        return UIImage.init(cgImage: newCGImage, scale: 1, orientation: .up)
    }
}
